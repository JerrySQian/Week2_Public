{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sleep_Analysis_Challenge_basicCNN_AZhao.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB6YunD0Gdgc",
        "colab_type": "text"
      },
      "source": [
        "# \"You Snooze, You Win\" Challenge\n",
        "\n",
        "Every year, the [PhysioNet/CinC (Computing in Cardiology) Challenge](https://www.physionet.org/challenge/) invites \"participants to tackle clinically interesting problems that are either unsolved or not well-solved.\" For this year's week 2 machine learning challenge, BWSI has revived a past PhysioNet challenge based on sleep classification.\n",
        "\n",
        "This year's challenge focuses on the classification of nonarousal and arousal timeframes. If you would like to understand the biological implications of the challenge, we recommend reading PhysioNet's [introduction](https://physionet.org/challenge/2018/) of the challenge.\n",
        "\n",
        "For this challenge, you will classify samples into 5 classes (Arousal, NREM1, NREM2, NREM3, REM). Each sample consists of seven physiological signals (O2-M1, E1-M2, Chin1-Chin2, ABD, CHEST, AIRFLOW, ECG) measured at 200 Hz over a 60 second period (12000 timepoints). In this notebook, we provide code to import the data, visualize sample signals, implement an example classifier, and 'score' your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ctSzKHoGr1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Import libraries ###\n",
        "\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "#set default plotting fonts\n",
        "font = {'family' : 'sans-serif',\n",
        "        'weight' : 'normal',\n",
        "        'size'   : 20}\n",
        "\n",
        "matplotlib.rc('font', **font)\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "\n",
        "#data preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#garbage collection (for saving RAM during training)\n",
        "import gc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XxIE6ZwGvjh",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Dataset\n",
        "\n",
        "This dataset is a modified version of the PhysioNet/CinC Challenge data, which were contributed by the Massachusetts General Hospitalâ€™s Computational Clinical Neurophysiology Laboratory, and the Clinical Data Animation Laboratory.\n",
        "***\n",
        "**Class labels:**\n",
        "- 0 = Arousal\n",
        "- 1 = NREM1\n",
        "- 2 = NREM2\n",
        "- 3 = NREM3\n",
        "- 4 = REM\n",
        "***\n",
        "**Class descriptions:**\n",
        "\n",
        "<img src=\"https://github.com/BeaverWorksMedlytics2020/Data_Public/blob/master/Images/Week2/sleepStagesTable.svg?raw=true\">\n",
        "\n",
        "***\n",
        "**Physiological signal description:**\n",
        "\n",
        "O2-M1 - posterior brain activity (electroencephalography)\n",
        "\n",
        "E1-M2 - left eye activity (electrooculography)\n",
        "\n",
        "Chin1-Chin2 - chin movement (electromyography)\n",
        "\n",
        "ABD - abdominal movement (electromyography)\n",
        "\n",
        "CHEST - chest movement (electromyography)\n",
        "\n",
        "AIRFLOW - respiratory airflow\n",
        "\n",
        "ECG - cardiac activity (electrocardiography)\n",
        "***\n",
        "Run both cell blocks to get the challenge data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfgbZPNYziXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "7392c6b8-89a7-422d-f316-b761b9e3f5a6"
      },
      "source": [
        "# Clone repo and move into data directory (only run this once)\n",
        "!git clone https://github.com/BeaverWorksMedlytics2020/Data_Public\n",
        "os.chdir('./Data_Public/ChallengeProjects/Week2/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Data_Public'...\n",
            "remote: Enumerating objects: 144, done.\u001b[K\n",
            "remote: Counting objects: 100% (144/144), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 5269 (delta 54), reused 60 (delta 23), pack-reused 5125\u001b[K\n",
            "Receiving objects: 100% (5269/5269), 1.11 GiB | 22.07 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n",
            "Checking out files: 100% (5130/5130), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qANF2BvQG2m3",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data in Memory\n",
        "Run the cell below to extract the raw training and test data. It may take a minute or two to run through. Here are the variables containing the data you will get:\n",
        "\n",
        "* **data_train**: np array shape (4000, 12000, 7). Contains 4000 samples (60s each) of 12000 data points (200Hz x 60s), for 7 different signals. \n",
        "* **labels_train**: np array shape (4000,). Contains ground truth labels for data_train. The order of the labels corresponds to the order of the training data.\n",
        "* **ID_train**: list of 4000 unique IDs. The order of the IDs corresponds to the order of the training data. \n",
        "* **data_test**: np array shape (1000, 12000, 7). Contains 1000 samples (60s each) of 12000 data points (200Hz x 60s), for 7 different signals.\n",
        "* **ID_test**: list of 1000 unique IDs. The order of the IDs corresponds to the order of the training data.\n",
        "\n",
        "We encourage you to print each of these variables to see what they look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rw8inOvG5QP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "20b04e10-8bd8-4f3d-a11f-94febacc818a"
      },
      "source": [
        "### Run once to import data ###\n",
        "\n",
        "def get_file_locs():\n",
        "    '''\n",
        "    find all files in 'training' and 'test' directories and put their names \n",
        "    under 'training' and 'test' keys in the file_dict dictionary\n",
        "    '''\n",
        "\n",
        "    file_dict = {'training':[], 'test':[]}\n",
        "    for data_type in file_dict:\n",
        "        for file in os.listdir('./' + data_type):\n",
        "            file_dict[data_type].append(data_type + '/' + file)\n",
        "    \n",
        "    return file_dict\n",
        "\n",
        "def get_sample_data(data_type, id_number):\n",
        "    '''\n",
        "    get signal data, label, and filename associated with given data type and index num\n",
        "\n",
        "    parameters:\n",
        "\n",
        "     data_type -- Dictates whether sample comes from training set or test set.\n",
        "                 This input must be either 'training' or 'test' (defaults to 'training')\n",
        "\n",
        "     id_number -- Which sample ID should be returned? Must be 0-3999 if data_type is 'training'\n",
        "                 or 0-999 if data_type is 'test' (defaults to random integer from 0-999)\n",
        "  \n",
        "    returns:\n",
        "\n",
        "     sample_data -- dataframe with 1 row and 2 columns-- column \"Signal\" contains a series object \n",
        "                    and column \"Label\" contains numeric label for that sample\n",
        "    '''\n",
        "    file = './' + data_type + '/' + str(id_number) + '.xz'\n",
        "\n",
        "    #sample_data is a dataframe with 1 row and 2 columns--\n",
        "    #\"Signal\" (contains a series object) and \"Label\" (contains numeric label)\n",
        "    sample_data = pd.read_pickle('./' + file)\n",
        "\n",
        "    return sample_data, file.split('/')[2]\n",
        "\n",
        "file_dict = get_file_locs()\n",
        "print(f\"{len(file_dict['training'])} training samples found, {len(file_dict['test'])} test samples found\")\n",
        "\n",
        "data_train = np.zeros((4000, 12000, 7))\n",
        "labels_train = np.zeros(4000)\n",
        "ID_train = []\n",
        "for i in range(4000):\n",
        "  sample_data, ID = get_sample_data('training', i)\n",
        "  data_train[i] = np.array(list(sample_data['Signal']), dtype=np.float).reshape(12000, 7)\n",
        "  labels_train[i] = np.array(list(sample_data['Label']), dtype=np.float)\n",
        "  ID_train.append(ID)\n",
        "  if(i%500==0):\n",
        "    print('Loading training sample ' + str(i))\n",
        "  \n",
        "data_test = np.zeros((1000, 12000, 7))\n",
        "ID_test = []\n",
        "for i in range(1000):\n",
        "  sample_data, ID = get_sample_data('test', i)\n",
        "  data_test[i] = np.array(list(sample_data['Signal']), dtype=np.float).reshape(12000, 7)\n",
        "  ID_test.append(ID)\n",
        "  if(i%500==0):\n",
        "    print('Loading test sample ' + str(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4000 training samples found, 1000 test samples found\n",
            "Loading training sample 0\n",
            "Loading training sample 500\n",
            "Loading training sample 1000\n",
            "Loading training sample 1500\n",
            "Loading training sample 2000\n",
            "Loading training sample 2500\n",
            "Loading training sample 3000\n",
            "Loading training sample 3500\n",
            "Loading test sample 0\n",
            "Loading test sample 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVNgpgciw6p4",
        "colab_type": "text"
      },
      "source": [
        "## Create One-Hot Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN0BBD3fHKRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Create label array for all training samples using categorical datatype ###\n",
        "\n",
        "train_labels = np.ndarray(shape = (1, 4000))\n",
        "\n",
        "#set labels to integers first\n",
        "for i in range(4000):\n",
        "    train_labels[0][i] = i//800 # This is a way to label each entry (since classes are in order)\n",
        "\n",
        "#convert labels to onehot, ensure type is float32\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels[0], 5).astype(np.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIzqcXmJBHdX",
        "colab_type": "text"
      },
      "source": [
        "## Shuffle and Partition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "buuR3HH9yTOw",
        "colab": {}
      },
      "source": [
        "### Shuffle and partition all train data\n",
        "\n",
        "#(Training data is ordered by default so shuffling before partitioning is important)\n",
        "\n",
        "#--Shuffle data_train--\n",
        "#(Note that data is only shuffled in first dimension, which is what we want)\n",
        "data_train, train_labels = shuffle(data_train, train_labels, random_state = 25, stratify = train_labels)\n",
        "\n",
        "#--Scale all labeled data in data_train--\n",
        "\n",
        "#initialize standard scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "#Standard scaler is meant for 2D arrays, so we reshape, scale, and then reshape again\n",
        "reshaped_X_train = data_train.reshape((data_train.shape[0]*data_train.shape[1], data_train.shape[2])).copy()\n",
        "reshaped_X_train = scaler.fit_transform(reshaped_X_train)\n",
        "data_train = reshaped_X_train.reshape((data_train.shape[0], data_train.shape[1], data_train.shape[2]))\n",
        "\n",
        "del reshaped_X_train #get rid of large temporary variable\n",
        "\n",
        "#--Scale unlabeled test data--\n",
        "#Because we scaled labeled data before training, we need to also scale test data --\n",
        "\n",
        "#Standard scaler is meant for 2D arrays, so we reshape, apply scaling, and then \n",
        "#reshape again to get back to original\n",
        "reshaped_X_test = data_test.reshape((data_test.shape[0]*data_test.shape[1], data_test.shape[2])).copy()\n",
        "reshaped_X_test = scaler.transform(reshaped_X_test)\n",
        "data_test = reshaped_X_test.reshape((data_test.shape[0], data_test.shape[1], data_test.shape[2]))\n",
        "\n",
        "del reshaped_X_test #get rid of large temporary variable\n",
        "\n",
        "#--create 3 partitions of provided training data--\n",
        "# Note we are breaking up provided labeled data into training, validation, and \"mock test\" sets\n",
        "\n",
        "val_size = 1000\n",
        "mocktest_size = 500\n",
        "\n",
        "mocktest_data = data_train[0:mocktest_size, :, :]\n",
        "mocktest_labels = train_labels[0:mocktest_size, :]\n",
        "\n",
        "val_data = data_train[mocktest_size:mocktest_size+val_size, :, :]\n",
        "val_labels = train_labels[mocktest_size:mocktest_size+val_size, :]\n",
        "\n",
        "partial_train_data = data_train[mocktest_size+val_size:,:,:]\n",
        "tr_labels = train_labels[mocktest_size+val_size:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOcj_uuUHP3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28057ee9-95b7-430b-dc7d-6d18ba8b9f92"
      },
      "source": [
        "### Run every time you change set of parameters ###\n",
        "\n",
        "class garbage_collect_callback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    gc.collect()\n",
        "\n",
        "#this will reset your model if you want to make changes, and just see the changes - JQ\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "\"\"\" Modify to your heart's and algorithm's content ^_^ \"\"\"\n",
        "model.add(tf.keras.layers.Conv1D(filters = 8, kernel_size = 5, padding = 'valid',\n",
        "                                activation=tf.nn.relu, \n",
        "                                input_shape=(partial_train_data.shape[1],partial_train_data.shape[2])))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.1))\n",
        "model.add(tf.keras.layers.Conv1D(filters = 8, kernel_size = 5, padding = 'valid',\n",
        "                                activation=tf.nn.relu, \n",
        "                                input_shape=(partial_train_data.shape[1],partial_train_data.shape[2])))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPooling1D(2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(filters = 16, kernel_size = 5, padding = 'valid',\n",
        "                                activation=tf.nn.relu, \n",
        "                                input_shape=(partial_train_data.shape[1],partial_train_data.shape[2])))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.1))\n",
        "model.add(tf.keras.layers.Conv1D(filters = 16, kernel_size = 5, padding = 'valid',\n",
        "                                activation=tf.nn.relu, \n",
        "                                input_shape=(partial_train_data.shape[1],partial_train_data.shape[2])))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPooling1D(2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(filters = 32, kernel_size = 3, padding = 'valid',\n",
        "                                activation=tf.nn.relu, \n",
        "                                input_shape=(partial_train_data.shape[1],partial_train_data.shape[2])))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.1))\n",
        "model.add(tf.keras.layers.Conv1D(filters = 32, kernel_size = 3, padding = 'valid',\n",
        "                                activation=tf.nn.relu, \n",
        "                                input_shape=(partial_train_data.shape[1],partial_train_data.shape[2])))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPooling1D(2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(filters = 64, kernel_size = 3, padding = 'valid',\n",
        "                                activation=tf.nn.relu, \n",
        "                                input_shape=(partial_train_data.shape[1],partial_train_data.shape[2])))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.1))\n",
        "model.add(tf.keras.layers.Conv1D(filters = 64, kernel_size = 3, padding = 'valid',\n",
        "                                activation=tf.nn.relu, \n",
        "                                input_shape=(partial_train_data.shape[1],partial_train_data.shape[2])))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPooling1D(2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv1D(filters = 128, kernel_size = 3, padding = 'valid',\n",
        "                                activation=tf.nn.relu, \n",
        "                                input_shape=(partial_train_data.shape[1],partial_train_data.shape[2])))\n",
        "\n",
        "#take maximum activation value from each convolution result and pass to next layer\n",
        "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
        "\n",
        "# we should end with a softmax to ensure outputs behave like probabilities\n",
        "#(i.e. sum to 1)\n",
        "model.add(tf.keras.layers.Dense(5, activation=tf.nn.softmax)) \n",
        "\n",
        "#opt = tf.keras.optimizers.RMSprop(learning_rate=0.001) #Definitely change this\n",
        "#Another potential optimizer\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "#opt = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "\n",
        "#opt = tf.keras.optimizers.\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(partial_train_data, # Train examples\n",
        "        tr_labels, # Train labels\n",
        "        epochs=200, # number of epochs (passes through data during training)\n",
        "        batch_size=100, # number of points to consider in each optimizer iteration\n",
        "        callbacks = [garbage_collect_callback()],\n",
        "        validation_data=(val_data, val_labels), #data to use for validation\n",
        "        verbose=1) #will print information about optimization process"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 11996, 8)          288       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 11996, 8)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11992, 8)          328       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 5996, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 5992, 16)          656       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5992, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 5988, 16)          1296      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 2994, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 2992, 32)          1568      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2992, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 2990, 32)          3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 1495, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 1493, 64)          6208      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1493, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 1491, 64)          12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 745, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 743, 128)          24704     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 63,245\n",
            "Trainable params: 63,245\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "25/25 [==============================] - 3s 114ms/step - loss: 1.6054 - accuracy: 0.2180 - val_loss: 1.6097 - val_accuracy: 0.2180\n",
            "Epoch 2/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 1.5984 - accuracy: 0.2264 - val_loss: 1.6070 - val_accuracy: 0.2180\n",
            "Epoch 3/200\n",
            "25/25 [==============================] - 3s 102ms/step - loss: 1.5923 - accuracy: 0.2424 - val_loss: 1.6026 - val_accuracy: 0.2250\n",
            "Epoch 4/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 1.5903 - accuracy: 0.2324 - val_loss: 1.6043 - val_accuracy: 0.2160\n",
            "Epoch 5/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 1.5872 - accuracy: 0.2824 - val_loss: 1.5979 - val_accuracy: 0.2480\n",
            "Epoch 6/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 1.5801 - accuracy: 0.2664 - val_loss: 1.5832 - val_accuracy: 0.2900\n",
            "Epoch 7/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 1.5736 - accuracy: 0.3052 - val_loss: 1.5851 - val_accuracy: 0.3570\n",
            "Epoch 8/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 1.5451 - accuracy: 0.3592 - val_loss: 1.5552 - val_accuracy: 0.3810\n",
            "Epoch 9/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.5142 - accuracy: 0.3748 - val_loss: 1.5507 - val_accuracy: 0.3540\n",
            "Epoch 10/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 1.4791 - accuracy: 0.3864 - val_loss: 1.5181 - val_accuracy: 0.3710\n",
            "Epoch 11/200\n",
            "25/25 [==============================] - 3s 102ms/step - loss: 1.4249 - accuracy: 0.4204 - val_loss: 1.4130 - val_accuracy: 0.4630\n",
            "Epoch 12/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.3323 - accuracy: 0.4644 - val_loss: 1.3293 - val_accuracy: 0.4690\n",
            "Epoch 13/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.2629 - accuracy: 0.4888 - val_loss: 1.2536 - val_accuracy: 0.5170\n",
            "Epoch 14/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 1.2163 - accuracy: 0.5028 - val_loss: 1.2031 - val_accuracy: 0.5300\n",
            "Epoch 15/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.1831 - accuracy: 0.5076 - val_loss: 1.1906 - val_accuracy: 0.5180\n",
            "Epoch 16/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.1515 - accuracy: 0.5340 - val_loss: 1.2584 - val_accuracy: 0.4780\n",
            "Epoch 17/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 1.1343 - accuracy: 0.5292 - val_loss: 1.1328 - val_accuracy: 0.5400\n",
            "Epoch 18/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.1101 - accuracy: 0.5400 - val_loss: 1.1176 - val_accuracy: 0.5390\n",
            "Epoch 19/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 1.0980 - accuracy: 0.5464 - val_loss: 1.1371 - val_accuracy: 0.5280\n",
            "Epoch 20/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 1.0910 - accuracy: 0.5452 - val_loss: 1.1072 - val_accuracy: 0.5550\n",
            "Epoch 21/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 1.0697 - accuracy: 0.5480 - val_loss: 1.0739 - val_accuracy: 0.5520\n",
            "Epoch 22/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.0547 - accuracy: 0.5528 - val_loss: 1.0783 - val_accuracy: 0.5570\n",
            "Epoch 23/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 1.0530 - accuracy: 0.5632 - val_loss: 1.1460 - val_accuracy: 0.5210\n",
            "Epoch 24/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.0326 - accuracy: 0.5708 - val_loss: 1.0609 - val_accuracy: 0.5620\n",
            "Epoch 25/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.0340 - accuracy: 0.5808 - val_loss: 1.2267 - val_accuracy: 0.4970\n",
            "Epoch 26/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.0853 - accuracy: 0.5520 - val_loss: 1.0692 - val_accuracy: 0.5520\n",
            "Epoch 27/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.0292 - accuracy: 0.5688 - val_loss: 1.0761 - val_accuracy: 0.5360\n",
            "Epoch 28/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.0284 - accuracy: 0.5732 - val_loss: 1.0907 - val_accuracy: 0.5430\n",
            "Epoch 29/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.0357 - accuracy: 0.5756 - val_loss: 1.0488 - val_accuracy: 0.5650\n",
            "Epoch 30/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 1.0055 - accuracy: 0.5844 - val_loss: 1.0385 - val_accuracy: 0.5870\n",
            "Epoch 31/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.0148 - accuracy: 0.5976 - val_loss: 1.0554 - val_accuracy: 0.5770\n",
            "Epoch 32/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 1.0045 - accuracy: 0.5872 - val_loss: 1.0478 - val_accuracy: 0.5570\n",
            "Epoch 33/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.9878 - accuracy: 0.6020 - val_loss: 1.1206 - val_accuracy: 0.5280\n",
            "Epoch 34/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 0.9764 - accuracy: 0.5944 - val_loss: 1.0640 - val_accuracy: 0.5560\n",
            "Epoch 35/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.9725 - accuracy: 0.5896 - val_loss: 1.0646 - val_accuracy: 0.5590\n",
            "Epoch 36/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.9895 - accuracy: 0.5948 - val_loss: 1.0539 - val_accuracy: 0.5660\n",
            "Epoch 37/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.9693 - accuracy: 0.6056 - val_loss: 1.0342 - val_accuracy: 0.5700\n",
            "Epoch 38/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.9466 - accuracy: 0.6180 - val_loss: 1.1141 - val_accuracy: 0.5580\n",
            "Epoch 39/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 0.9439 - accuracy: 0.6104 - val_loss: 1.0293 - val_accuracy: 0.5760\n",
            "Epoch 40/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.9488 - accuracy: 0.6124 - val_loss: 1.1351 - val_accuracy: 0.5560\n",
            "Epoch 41/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.9425 - accuracy: 0.6100 - val_loss: 1.0553 - val_accuracy: 0.5720\n",
            "Epoch 42/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.9364 - accuracy: 0.6168 - val_loss: 1.1419 - val_accuracy: 0.5510\n",
            "Epoch 43/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.9374 - accuracy: 0.6104 - val_loss: 1.0362 - val_accuracy: 0.5550\n",
            "Epoch 44/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.9243 - accuracy: 0.6292 - val_loss: 1.0794 - val_accuracy: 0.5590\n",
            "Epoch 45/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.9262 - accuracy: 0.6256 - val_loss: 1.0283 - val_accuracy: 0.5740\n",
            "Epoch 46/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.9175 - accuracy: 0.6232 - val_loss: 1.0482 - val_accuracy: 0.5730\n",
            "Epoch 47/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.9152 - accuracy: 0.6320 - val_loss: 1.0093 - val_accuracy: 0.5920\n",
            "Epoch 48/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.9031 - accuracy: 0.6316 - val_loss: 1.0503 - val_accuracy: 0.5820\n",
            "Epoch 49/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.9217 - accuracy: 0.6316 - val_loss: 1.1285 - val_accuracy: 0.5470\n",
            "Epoch 50/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.9148 - accuracy: 0.6352 - val_loss: 1.1155 - val_accuracy: 0.5400\n",
            "Epoch 51/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.8957 - accuracy: 0.6316 - val_loss: 1.0304 - val_accuracy: 0.5760\n",
            "Epoch 52/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.8782 - accuracy: 0.6372 - val_loss: 0.9644 - val_accuracy: 0.6190\n",
            "Epoch 53/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.8848 - accuracy: 0.6484 - val_loss: 1.0620 - val_accuracy: 0.5880\n",
            "Epoch 54/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.8603 - accuracy: 0.6468 - val_loss: 1.0411 - val_accuracy: 0.5790\n",
            "Epoch 55/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.8534 - accuracy: 0.6564 - val_loss: 1.0327 - val_accuracy: 0.5870\n",
            "Epoch 56/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.8680 - accuracy: 0.6468 - val_loss: 1.0062 - val_accuracy: 0.5930\n",
            "Epoch 57/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.8730 - accuracy: 0.6544 - val_loss: 0.9663 - val_accuracy: 0.6270\n",
            "Epoch 58/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.8829 - accuracy: 0.6464 - val_loss: 1.0140 - val_accuracy: 0.5830\n",
            "Epoch 59/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.8562 - accuracy: 0.6516 - val_loss: 1.0847 - val_accuracy: 0.5750\n",
            "Epoch 60/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.8442 - accuracy: 0.6544 - val_loss: 0.9731 - val_accuracy: 0.6080\n",
            "Epoch 61/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.8567 - accuracy: 0.6624 - val_loss: 0.9513 - val_accuracy: 0.6260\n",
            "Epoch 62/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.8355 - accuracy: 0.6684 - val_loss: 1.0004 - val_accuracy: 0.5990\n",
            "Epoch 63/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.8386 - accuracy: 0.6648 - val_loss: 1.0266 - val_accuracy: 0.5910\n",
            "Epoch 64/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.8579 - accuracy: 0.6564 - val_loss: 1.0519 - val_accuracy: 0.5930\n",
            "Epoch 65/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.8138 - accuracy: 0.6720 - val_loss: 1.0972 - val_accuracy: 0.5730\n",
            "Epoch 66/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.8157 - accuracy: 0.6696 - val_loss: 1.0137 - val_accuracy: 0.6110\n",
            "Epoch 67/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.8278 - accuracy: 0.6712 - val_loss: 1.0145 - val_accuracy: 0.6040\n",
            "Epoch 68/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.8382 - accuracy: 0.6680 - val_loss: 1.0316 - val_accuracy: 0.6060\n",
            "Epoch 69/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.8098 - accuracy: 0.6780 - val_loss: 1.0491 - val_accuracy: 0.6010\n",
            "Epoch 70/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.8071 - accuracy: 0.6768 - val_loss: 1.0034 - val_accuracy: 0.6050\n",
            "Epoch 71/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.8201 - accuracy: 0.6696 - val_loss: 0.9582 - val_accuracy: 0.6270\n",
            "Epoch 72/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.7926 - accuracy: 0.6916 - val_loss: 1.0215 - val_accuracy: 0.6120\n",
            "Epoch 73/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.7975 - accuracy: 0.6964 - val_loss: 0.9775 - val_accuracy: 0.6310\n",
            "Epoch 74/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.8436 - accuracy: 0.6564 - val_loss: 0.9618 - val_accuracy: 0.6180\n",
            "Epoch 75/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.7888 - accuracy: 0.6896 - val_loss: 1.1069 - val_accuracy: 0.5990\n",
            "Epoch 76/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.7817 - accuracy: 0.6824 - val_loss: 0.9633 - val_accuracy: 0.6310\n",
            "Epoch 77/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.7610 - accuracy: 0.7000 - val_loss: 0.9917 - val_accuracy: 0.6110\n",
            "Epoch 78/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.7616 - accuracy: 0.6944 - val_loss: 1.0435 - val_accuracy: 0.5940\n",
            "Epoch 79/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.7443 - accuracy: 0.7148 - val_loss: 1.0122 - val_accuracy: 0.6370\n",
            "Epoch 80/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.7493 - accuracy: 0.6972 - val_loss: 0.9637 - val_accuracy: 0.6290\n",
            "Epoch 81/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.8109 - accuracy: 0.6728 - val_loss: 1.0061 - val_accuracy: 0.6060\n",
            "Epoch 82/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.7767 - accuracy: 0.6944 - val_loss: 1.0139 - val_accuracy: 0.6150\n",
            "Epoch 83/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.7534 - accuracy: 0.6960 - val_loss: 0.9655 - val_accuracy: 0.6290\n",
            "Epoch 84/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.7240 - accuracy: 0.7124 - val_loss: 0.9723 - val_accuracy: 0.6320\n",
            "Epoch 85/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.7205 - accuracy: 0.7204 - val_loss: 1.0554 - val_accuracy: 0.6160\n",
            "Epoch 86/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.7588 - accuracy: 0.6968 - val_loss: 1.0001 - val_accuracy: 0.6230\n",
            "Epoch 87/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.7213 - accuracy: 0.7124 - val_loss: 1.0128 - val_accuracy: 0.6210\n",
            "Epoch 88/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.7323 - accuracy: 0.7036 - val_loss: 1.0243 - val_accuracy: 0.6450\n",
            "Epoch 89/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.7234 - accuracy: 0.7152 - val_loss: 0.9875 - val_accuracy: 0.6260\n",
            "Epoch 90/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.7088 - accuracy: 0.7180 - val_loss: 1.0204 - val_accuracy: 0.6310\n",
            "Epoch 91/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.7335 - accuracy: 0.7120 - val_loss: 1.0036 - val_accuracy: 0.6300\n",
            "Epoch 92/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.6864 - accuracy: 0.7268 - val_loss: 1.0041 - val_accuracy: 0.6230\n",
            "Epoch 93/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6989 - accuracy: 0.7256 - val_loss: 1.0112 - val_accuracy: 0.6310\n",
            "Epoch 94/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.6847 - accuracy: 0.7328 - val_loss: 1.0011 - val_accuracy: 0.6470\n",
            "Epoch 95/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.7078 - accuracy: 0.7256 - val_loss: 0.9887 - val_accuracy: 0.6460\n",
            "Epoch 96/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.7055 - accuracy: 0.7296 - val_loss: 1.1693 - val_accuracy: 0.6030\n",
            "Epoch 97/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.7072 - accuracy: 0.7248 - val_loss: 1.0143 - val_accuracy: 0.6290\n",
            "Epoch 98/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6934 - accuracy: 0.7248 - val_loss: 1.1146 - val_accuracy: 0.6020\n",
            "Epoch 99/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.6877 - accuracy: 0.7268 - val_loss: 1.0013 - val_accuracy: 0.6380\n",
            "Epoch 100/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6895 - accuracy: 0.7328 - val_loss: 1.0240 - val_accuracy: 0.6240\n",
            "Epoch 101/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6823 - accuracy: 0.7256 - val_loss: 0.9983 - val_accuracy: 0.6500\n",
            "Epoch 102/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6861 - accuracy: 0.7264 - val_loss: 1.0608 - val_accuracy: 0.6410\n",
            "Epoch 103/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.6612 - accuracy: 0.7408 - val_loss: 1.0338 - val_accuracy: 0.6360\n",
            "Epoch 104/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6527 - accuracy: 0.7404 - val_loss: 1.0782 - val_accuracy: 0.6330\n",
            "Epoch 105/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6635 - accuracy: 0.7360 - val_loss: 0.9949 - val_accuracy: 0.6390\n",
            "Epoch 106/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.6664 - accuracy: 0.7400 - val_loss: 1.0466 - val_accuracy: 0.6360\n",
            "Epoch 107/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6758 - accuracy: 0.7408 - val_loss: 1.0601 - val_accuracy: 0.6130\n",
            "Epoch 108/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6631 - accuracy: 0.7432 - val_loss: 1.0080 - val_accuracy: 0.6350\n",
            "Epoch 109/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.7203 - accuracy: 0.7232 - val_loss: 1.0185 - val_accuracy: 0.6410\n",
            "Epoch 110/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.6587 - accuracy: 0.7464 - val_loss: 1.1108 - val_accuracy: 0.6270\n",
            "Epoch 111/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.6326 - accuracy: 0.7528 - val_loss: 1.0839 - val_accuracy: 0.6330\n",
            "Epoch 112/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.6334 - accuracy: 0.7532 - val_loss: 1.0832 - val_accuracy: 0.6110\n",
            "Epoch 113/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.6305 - accuracy: 0.7512 - val_loss: 1.0952 - val_accuracy: 0.6450\n",
            "Epoch 114/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.6204 - accuracy: 0.7596 - val_loss: 1.0615 - val_accuracy: 0.6320\n",
            "Epoch 115/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.6051 - accuracy: 0.7568 - val_loss: 1.1811 - val_accuracy: 0.6100\n",
            "Epoch 116/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6223 - accuracy: 0.7608 - val_loss: 1.0836 - val_accuracy: 0.6470\n",
            "Epoch 117/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6022 - accuracy: 0.7692 - val_loss: 1.0335 - val_accuracy: 0.6240\n",
            "Epoch 118/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.5934 - accuracy: 0.7648 - val_loss: 1.0884 - val_accuracy: 0.6460\n",
            "Epoch 119/200\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 0.5931 - accuracy: 0.7676 - val_loss: 1.1137 - val_accuracy: 0.6310\n",
            "Epoch 120/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5850 - accuracy: 0.7756 - val_loss: 1.1162 - val_accuracy: 0.6380\n",
            "Epoch 121/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.5583 - accuracy: 0.7864 - val_loss: 1.0478 - val_accuracy: 0.6430\n",
            "Epoch 122/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6009 - accuracy: 0.7704 - val_loss: 1.1635 - val_accuracy: 0.6100\n",
            "Epoch 123/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.5653 - accuracy: 0.7800 - val_loss: 1.0693 - val_accuracy: 0.6390\n",
            "Epoch 124/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5505 - accuracy: 0.7868 - val_loss: 1.0850 - val_accuracy: 0.6290\n",
            "Epoch 125/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.5600 - accuracy: 0.7868 - val_loss: 1.1614 - val_accuracy: 0.6350\n",
            "Epoch 126/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.6196 - accuracy: 0.7556 - val_loss: 1.0506 - val_accuracy: 0.6280\n",
            "Epoch 127/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5574 - accuracy: 0.7896 - val_loss: 1.0992 - val_accuracy: 0.6380\n",
            "Epoch 128/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5491 - accuracy: 0.7848 - val_loss: 1.0681 - val_accuracy: 0.6550\n",
            "Epoch 129/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5266 - accuracy: 0.7940 - val_loss: 1.2070 - val_accuracy: 0.6190\n",
            "Epoch 130/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.5441 - accuracy: 0.7892 - val_loss: 1.1810 - val_accuracy: 0.6420\n",
            "Epoch 131/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5438 - accuracy: 0.7876 - val_loss: 1.1390 - val_accuracy: 0.6160\n",
            "Epoch 132/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.5413 - accuracy: 0.7908 - val_loss: 1.1040 - val_accuracy: 0.6420\n",
            "Epoch 133/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5339 - accuracy: 0.7944 - val_loss: 1.1341 - val_accuracy: 0.6330\n",
            "Epoch 134/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.5431 - accuracy: 0.7808 - val_loss: 1.0990 - val_accuracy: 0.6500\n",
            "Epoch 135/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5592 - accuracy: 0.7796 - val_loss: 1.0883 - val_accuracy: 0.6460\n",
            "Epoch 136/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5199 - accuracy: 0.7916 - val_loss: 1.0963 - val_accuracy: 0.6460\n",
            "Epoch 137/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.5404 - accuracy: 0.7904 - val_loss: 1.0936 - val_accuracy: 0.6420\n",
            "Epoch 138/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.4873 - accuracy: 0.8064 - val_loss: 1.2000 - val_accuracy: 0.6280\n",
            "Epoch 139/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.5139 - accuracy: 0.7968 - val_loss: 1.1450 - val_accuracy: 0.6430\n",
            "Epoch 140/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.5250 - accuracy: 0.7916 - val_loss: 1.2292 - val_accuracy: 0.6300\n",
            "Epoch 141/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.4859 - accuracy: 0.8084 - val_loss: 1.1125 - val_accuracy: 0.6360\n",
            "Epoch 142/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.4976 - accuracy: 0.8016 - val_loss: 1.2197 - val_accuracy: 0.6290\n",
            "Epoch 143/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.5244 - accuracy: 0.7948 - val_loss: 1.1724 - val_accuracy: 0.6260\n",
            "Epoch 144/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.4813 - accuracy: 0.8140 - val_loss: 1.1290 - val_accuracy: 0.6450\n",
            "Epoch 145/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.4541 - accuracy: 0.8264 - val_loss: 1.2229 - val_accuracy: 0.6350\n",
            "Epoch 146/200\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.4862 - accuracy: 0.8084 - val_loss: 1.3166 - val_accuracy: 0.6150\n",
            "Epoch 147/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5098 - accuracy: 0.7928 - val_loss: 1.1601 - val_accuracy: 0.6420\n",
            "Epoch 148/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.4766 - accuracy: 0.8160 - val_loss: 1.2423 - val_accuracy: 0.6320\n",
            "Epoch 149/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5080 - accuracy: 0.7920 - val_loss: 1.1931 - val_accuracy: 0.6320\n",
            "Epoch 150/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5141 - accuracy: 0.7924 - val_loss: 1.1859 - val_accuracy: 0.6390\n",
            "Epoch 151/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.4651 - accuracy: 0.8248 - val_loss: 1.2207 - val_accuracy: 0.6510\n",
            "Epoch 152/200\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.4547 - accuracy: 0.8208 - val_loss: 1.2214 - val_accuracy: 0.6330\n",
            "Epoch 153/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.4576 - accuracy: 0.8188 - val_loss: 1.2034 - val_accuracy: 0.6440\n",
            "Epoch 154/200\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.4460 - accuracy: 0.8240 - val_loss: 1.2703 - val_accuracy: 0.6440\n",
            "Epoch 155/200\n",
            "22/25 [=========================>....] - ETA: 0s - loss: 0.4326 - accuracy: 0.8359"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRk6Xh_LHTXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8ca0ef38-af17-4edc-a0c4-6c2837733e84"
      },
      "source": [
        "### Run once after you have finished training your model ###\n",
        "#Reminder: Please ensure order of test data points has not been changed.\n",
        "\n",
        "#-- Evaluate model for test data --\n",
        "test_pred = model.predict(data_test)\n",
        "test_output = np.ndarray(shape = (1000, 6))\n",
        "\n",
        "#-- Write test output to dataframe and save to pickle file --\n",
        "test_dataframe = pd.DataFrame(test_output)\n",
        "\n",
        "file = 'unladen_swallow.xz'\n",
        "test_dataframe.to_pickle(file)\n",
        "test_dataframe = pd.DataFrame(test_output)\n",
        "os.listdir('.')\n",
        "files.download(file)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0deb80dc-5335-438f-ae3a-fb8575e33369\", \"unladen_swallow.xz\", 5212)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bduvOuTtHVfK",
        "colab_type": "text"
      },
      "source": [
        "## Submitting Your Model\n",
        "\n",
        "After training your classifier, run it on the test data to generate your predictions. Each class for a test sample should have an associated probability (between 0 and 1). Below are the parameters for the prediction format and export:\n",
        "\n",
        "- Your predictions should be in a pandas dataframe with 5 columns (classes) and 1000 rows (samples). Note that your predictions must follow the original test sample order (0.xz, 1.xz, 2.xz, ...). You only need to worry about this if you shuffled the test samples or stored the samples in an unordered data structure (dictionaries and sets). If this is the case, you should 1) add a separate column in your pandas dataframe with the file number for each sample; 2) sort the dataframe using this column; and 3) drop the column. These steps have been noted in the code below.\n",
        "- The predictions dataframe should be exported as an .xz file using dataframe.to_pickle() followed by files.download().\n",
        "\n",
        "Example code of the prediction format and export is presented in the cell block below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TiEUxHcZz_D",
        "colab_type": "text"
      },
      "source": [
        "Your model will be evaluated on Area Under the ROC Curve (ROCAUC), Matthews Correlation Coefficient (MCC) and creativity. There will be a \"winning\" group for each of these categories.\n",
        "\n",
        "If you are finished early, consider trying other ML algorithms and/or implementing multiple feature extraction methods. You can also help other groups if you finish early."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDQWbhUK6cMt",
        "colab_type": "text"
      },
      "source": [
        "## How Your Model Will Be Evaluated\n",
        "\n",
        "- **Area Under the ROC Curve (AUCROC)**: The receiver operating characteristic (ROC) curve plots the true positive rate (sensitivity/recall) against the false positive rate (fall-out) at many decision threshold settings. The area under the curve (AUC) measures discrimination, the classifier's ability to correctly identify samples from the \"positive\" and \"negative\" cases. Intuitively, AUC is the probability that a randomly chosen \"positive\" sample will be labeled as \"more positive\" than a randomly chosen \"negative\" sample. In the case of a multi-class ROC curve, each class is considered separately before taking the weighted average of all the class results. Simply put, the class under consideration is labeled as \"positive\" while all other classes are labeled as \"negative.\" Below is the multi-class ROC curve for the example classifier. The AUCROC score should be between 0 and 1, in which 0.5 is random classification and 1 is perfect classification.\n",
        "\n",
        "<img src=\"https://github.com/BeaverWorksMedlytics2020/Data_Public/blob/master/Images/Week2/MultiClassRocCurve_exampleClassifier.png?raw=true\" width=\"600\" height=\"500\">\n",
        "\n",
        "- **Matthews Correlation Coefficient (MCC)**: The MCC measures the quality of binary classifications, irrespective of the class sizes. Importantly, it is typically regarded as a balanced measure since it considers all values in the 2x2 contingency table (TP, FP, TN, FN). For this challenge, the binary classes will be \"Arousal\" (Arousal) and \"Nonarousal\" (NREM1, NREM2, NREM3, REM). The MCC score should be between -1 and 1, in which 0 is random classification and 1 is perfect classification.\n",
        "\n",
        " ![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/5caa90fc15105b74b59a30bbc9cc2e5bd43a13b7)\n",
        "\n",
        "Using these metrics, the example classifier has the following scores on test data:\n",
        "- AUCROC: 0.727\n",
        "- MCC: 0.163\n",
        "- Creativity: ( Í¡Â° ÍœÊ– Í¡Â°)\n",
        "\n",
        "Below is the code used to calculate the AUCROC and MCC metrics when evaluating your classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOpioHig8688",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = pd.DataFrame(model.predict(mocktest_data))\n",
        "test_predict = test_pred.idxmax(axis=1)\n",
        "test_labels = [ np.where(label==1)[0][0] for label in mocktest_labels]\n",
        "test_labels_one_hot = pd.DataFrame(mocktest_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIlfwfksLp-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "106c776f-a23b-4f4e-b227-285138d9ae93"
      },
      "source": [
        "fpr = {}\n",
        "tpr = {}\n",
        "roc_auc = {}\n",
        "\n",
        "\"\"\" Initalize key reference dictionaries \"\"\"\n",
        "sig_dict = {0:'O2-M1', 1:'E1-M2', 2:'Chin1-Chin2', 3:'ABD', 4:'CHEST', 5:'AIRFLOW', 6:'ECG'}\n",
        "sig_type_dict = {0:'Time (s)', 1:'Frequency (Hz)'}\n",
        "stage_dict = {0:'Arousal', 1:'NREM1', 2:'NREM2', 3:'NREM3', 4:'REM'}\n",
        "\n",
        "plt.figure(figsize=(14,10))\n",
        "for i in range(5):\n",
        "    fpr[i], tpr[i], _ = metrics.roc_curve(test_labels_one_hot.iloc[:, i], test_pred.iloc[:, i])\n",
        "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
        "    plt.plot(fpr[i], tpr[i], label = stage_dict[i] + ', ' + str(i))\n",
        "\n",
        "plt.plot([0, 1], [0, 1])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multi-Class ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(test_labels_one_hot.values.ravel(), test_pred.values.ravel())\n",
        "roc_auc_agg = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO1I5lme8oya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "for i in range(test_pred.shape[0]):\n",
        "    if test_predict.iloc[i]==0: y_pred.append(1)\n",
        "    else: y_pred.append(-1)\n",
        "    if test_labels[i]==0: y_true.append(1)\n",
        "    else: y_true.append(-1)\n",
        "mcc = metrics.matthews_corrcoef(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo7edcTTC6yD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fe5c7f9-bebe-4d35-fca6-174c45d3457d"
      },
      "source": [
        "print(roc_auc_agg, mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.896783 0.42090100827386784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6j_GmhqpqLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}